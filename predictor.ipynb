{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('strokeData.csv')\n",
    "\n",
    "#check for null \n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fill missing values for bmi using median as more accurate, as mean skewed\n",
    "by extreme data and mode can be skewed by outliers\n",
    "\"\"\"\n",
    "data['bmi'].fillna(data['bmi'].median(), inplace=True)\n",
    "data.head()\n",
    "\n",
    "#count how many stroke and non stroke for class balance\n",
    "strokes = data['stroke'].value_counts()\n",
    "#print(strokes)\n",
    "\n",
    "'''\n",
    "as the class imbalance is huge SMOTE is needed to artificially balance it out\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop non essential data that would be used to predict stroke, use new data frame\n",
    "dataFiltered = data.copy()\n",
    "#stroke dropped as we are predicting and id is identifier and no related\n",
    "dataFiltered.drop(['id'],axis=1,inplace=True)\n",
    "'''encode the data as categorical data is not allowed in machine learning\n",
    "hot encoding as no order or hierarchy\n",
    "'''\n",
    "dataFiltered = pd.get_dummies(dataFiltered, columns=['gender','ever_married','work_type','Residence_type','smoking_status'])\n",
    "\n",
    "#correlation test to see what to drop\n",
    "dataFiltered.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target and input data\n",
    "predictors = dataFiltered.drop(columns=['stroke'])\n",
    "target = dataFiltered['stroke']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE before train-test split\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(predictors, target)\n",
    "\n",
    "#split data into test and train data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.3,random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using hyper parameters - gridSearchcv for best resutls\n",
    "from sklearn.model_selection import GridSearchCV # type: ignore\n",
    "from sklearn.ensemble import RandomForestClassifier # type: ignore\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [100,200,300,400,500],\n",
    "    'max_depth': [None,10,20,30],\n",
    "}\n",
    "\n",
    "\n",
    "#fit model using gridsearch\n",
    "#cv = cross validation, spliting data into training and validation sets multiple times in diff ways\n",
    "#verbose - level of feedback\n",
    "grid = GridSearchCV(estimator=rf, param_grid=param_grid,cv=5,scoring='accuracy', n_jobs=-1,verbose=1)\n",
    "\n",
    "grid.fit(X_train_resampled,y_train_resampled)\n",
    "\n",
    "print(grid.best_params_)\n",
    "best_params = grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = grid.best_score_\n",
    "print(\"Best Cross-Validation Accuracy:\", best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing a better forest model using those best parameters\n",
    "optimizedRf = RandomForestClassifier(**best_params)\n",
    "\n",
    "#training model\n",
    "optimizedRf.fit(X_train,y_train)\n",
    "#prediciting model\n",
    "y_prediction = optimizedRf.predict(X_test)\n",
    "optimizedAccuracy = accuracy_score(y_test, y_prediction)\n",
    "optimizedR_squared = rf.score(X_test,y_train)\n",
    "\n",
    "print(optimizedAccuracy)\n",
    "print(optimizedR_squared)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
